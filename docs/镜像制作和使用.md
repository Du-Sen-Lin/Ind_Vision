# 算法

## 一、前置

### 1、C++/Python部署方案选择

```
1GB=1024MB (兆字节)1MB=1024KB (千字节)1KB=1024Byte (字节)1Byte=8bit (比特,或 位）
2048x2448黑白图像大小：2048x2448/1024/1024=4.78M
```

C++: 

调用方式：Java通过JNI调用C/C++编译链接后的动态链接库实现对C/C++调用。

1、系统与算法数据传输方式：内存，会更快；

2、推理速度会更快；

3、推理代码较复杂：模型的转换；不支持的算子改写；模型的压缩、量化；解决可能的精度下降问题；

4、可尝试的算法方案有限，对于有些算法方案不能部署或部署难度很大；

Python: 

调用方式：https 请求

1、系统与算法数据传输方式：硬盘读写图片，较慢；

2、推理速度相比C++ 减慢；

3、可尝试的算法方案更多，部署难度低。可快速验证算法方案和部署。

**raw格式数据的读写耗时测试：8kx16k uint8 写操作100ms左右；读图操作30ms左右。**

### 2、Python部署demo

算法与系统接口协议：HTTP

```
# flask
pip install flask 
```

### 3、环境部署

#### 3-1、基础docker：wdcv

```
docker commit 467318efc633 bpglass
docker save -o bpglass-save.tar bpglass
scp -r -P 7008 bpglass-save.tar user@183.56.181.50:/home/user/algo
docker load -i bpglass-save.tar

sudo nvidia-docker run -dit --name bp_algo -p 9322:22 -p 9330-9399:9330-9399 -v /etc/localtime:/etc/localtime -v /var/wdcvlm:/var/wdcvlm -v /var/tscvlm:/var/tscvlm -v /etc/machine-id:/etc/machine-id -v /data/algorithm/bp_algo/dataset/public:/root/dataset/public -v /data/algorithm/bp_algo/dataset/bp_algo:/root/dataset/bp_algo -v /data/algorithm/bp_algo/project/bp_algo:/root/project/bp_algo -v /data/algorithm/bp_algo/shared:/root/shared -v /data/algorithm/bp_algo/common/pretrained/_.torch:/root/.torch -v /data/algorithm/bp_algo/common/pretrained/_.cache:/root/.cache -v /dev/shm:/dev/shm --privileged bpglass:latest

docker exec -it bp_algo bash

#wdcv 开源
python setup.py bdist_wheel
scp -r -P 7008 wdcv-0.0.1-py3-none-any.whl user@183.56.181.50:/data/algorithm/bp_algo/project/bp_algo
scp -r -P 7008 bpglass user@183.56.181.50:/data/algorithm/bp_algo/project/bp_algo

# 启动http服务
python algo_service.py

# （可以修改~/.bashrc实现）
conda deactivate && conda activate ts_env

# commit 删除容器：docker rm 删除镜像：docker rmi
docker commit de7734c9fbf4 bpglass:1.0
```

#### 3-2、算法与系统接口调试

##### 1、自启动脚本 （docker compose）：

```yaml
version: '3'  # 指定 Compose 文件版本
services:  # 定义服务
  web:  # 服务名称
    build: ./web  # 构建镜像的路径
    ports:
      - 8080:80  # 将主机的8080端口映射到容器的80端口
    volumes:
      - ./web:/app  # 将主机的./web目录挂载到容器的/app目录
    depends_on:
      - db  # web服务依赖于db服务
  db:
    image: mysql:5.7  # 使用MySQL 5.7镜像
    environment:
      - MYSQL_ROOT_PASSWORD=secret  # 设置MySQL根密码
networks:  # 定义网络
  mynetwork:  # 网络名称
    driver: bridge  # 使用桥接网络驱动
```

example:

```

```



##### 2、docker 命令(--restart=always)：

```shell
# --restart=always docker --restart=always 是一个Docker命令的选项，用于在容器启动时自动重启容器。当设置了该选项后，无论是手动停止容器还是系统重启，Docker都会自动重新启动被标记为 --restart=always 的容器。
sudo nvidia-docker run -dit --name bp_algo -p 9322:22 -p 9330-9399:9330-9399 -v /etc/localtime:/etc/localtime -v /var/wdcvlm:/var/wdcvlm -v /var/tscvlm:/var/tscvlm -v /etc/machine-id:/etc/machine-id -v /data/algorithm/bp_algo/dataset/public:/root/dataset/public -v /data/algorithm/bp_algo/dataset/bp_algo:/root/dataset/bp_algo -v /data/algorithm/bp_algo/project/bp_algo:/root/project/bp_algo -v /data/algorithm/bp_algo/shared:/root/shared -v /data/algorithm/bp_algo/common/pretrained/_.torch:/root/.torch -v /data/algorithm/bp_algo/common/pretrained/_.cache:/root/.cache -v /dev/shm:/dev/shm --privileged bpglass:1.0
```



## 二、算法开发

### 1、wdcv



### 2、yolov5

```python
# 环境安装和验证
git clone https://github.com/ultralytics/yolov5
pip install -r requirements.txt
python3 detect.py --weights yolov5s.pt --source data/images/bus.jpg --device 0

# 训练
python train.py --data data/hayao.yaml --cfg models/hayao_yolov5s.yaml --weight pretrained/yolov5s.pt --epochs 100 --batch-size 16 --device 0,1
python train.py --data data/hayao.yaml --cfg models/hayao_yolov5s.yaml --weight runs/train/exp/weights/last.pt --epochs 10 --batch-size 16 --device 0,1

# 测试
python detect.py --weights /root/project/wdcv/common/WDCV/wdcv/re_algo/detection/yolo/yolov5/runs/train/exp/weights/best.pt --source /root/dataset/public/dataset_yolo/images/val/Image_20230310171432581.bmp --device 0
# Image_20230310171144605.bmp
python detect.py --weights /root/project/cv_algo/commom/WDCV/wdcv/re_algo/detection/yolo/yolov5/runs/train/exp4/weights/best.pt --source /root/dataset/public/dataset_yolo/images/val/Image_20230310171144605.bmp --device 0

# 转onnx
python export.py --data data/hayao.yaml --weights runs/train/exp/weights/best.pt --include onnx --device 0 --opset 12
```

```
python train.py -d configs/data/coco2017.yaml -c configs/model/yolov7/yolov7.yaml
```



```

```



## 三、缺陷生成

```
git clone https://github.com/CompVis/stable-diffusion.git

conda env create -f environment.yaml
conda activate ldm

pip config set global.index-url pypi.mirrors.ustc.edu.cn
pip config set install.trusted-host https://pypi.mirrors.ustc.edu.cn/simple/

pip install diffusers opencv-python==4.1.2.30 pudb==2019.2 invisible-watermark imageio==2.9.0 imageio-ffmpeg==0.4.2 pytorch-lightning==1.4.2 omegaconf==2.1.1 test-tube>=0.7.5 streamlit>=0.73.1 einops==0.3.0 torch-fidelity==0.3.0 transformers==4.19.2 torchmetrics==0.6.0 kornia==0.6
```





## 四、镜像制作

docker一般都是使用基于CPU的应用，而如果是GPU的话，就需要安装特有的硬件环境，比如需要安装nvidia driver。所以docker容器并不直接支持Nvidia GPU。为了使docker image能很便利的使用Nvidia GPU，从而产生了nvidia-docker，由它来制作nvidia driver的image。

### 1、命令创建镜像【用于部署】

Docker 官方维护了一个公共仓库 **[Docker Hub](https://link.zhihu.com/?target=https%3A//hub.docker.com/)**，里边包含了大多数我们需要的基础镜像。

首先注册一个账号，然后在本地登录：

```text
# wood 1947885050@qq.com pw:1123581321
sudo docker login
```

登录成功之后，我们就可以从docker hub上直接拉取自己账号下的全部镜像。

基础镜像：nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

```shell
# 前置：拉取镜像太慢 https://blog.csdn.net/weixin_43117620/article/details/129217954
# 参考：https://www.tnnidm.com/install-nvidia-docker-in-ubuntu/
# 可以通过修改Docker配置文件或使用docker pull命令的--registry-mirror参数来设置镜像源。下面示例chatgpt答案。
/etc/docker/daemon.json配置源

# devel:有cuda的nvcc包,涵盖了开发所需要的所有工具； runtime:只涵盖了运行环境的最小集合，例如动态库等,size会小很多。
docker pull nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

# 创建容器
nvidia-docker run -dit --name cv_algo -p 8322:22 -p 8330-8399:8330-8399 -v /etc/localtime:/etc/localtime -v /var/wdcvlm:/var/wdcvlm -v /var/tscvlm:/var/tscvlm -v /etc/machine-id:/etc/machine-id -v /data/algorithm/cv_algo/dataset/public:/root/dataset/public -v /data/algorithm/cv_algo/dataset/cv_algo:/root/dataset/cv_algo -v /data/algorithm/cv_algo/project/cv_algo:/root/project/cv_algo -v /data/algorithm/cv_algo/shared:/root/shared -v /data/algorithm/cv_algo/common/pretrained/_.torch:/root/.torch -v /data/algorithm/cv_algo/common/pretrained/_.cache:/root/.cache -v /dev/shm:/dev/shm --privileged nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

docker exec -it cv_algo bash

# 安装基础包：
apt-get update
apt-get install -y vim wget zip unrar tree git rsync ssh htop inetutils-ping net-tools libgl1-mesa-glx language-pack-zh-han*
echo "LANG=zh_CN.UTF-8" > /etc/default/locale

sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
mkdir -p /var/run/sshd && echo root:getech | chpasswd

wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && echo " wget ~/Miniconda3.sh done"

/bin/bash ~/miniconda.sh -b -p /root/conda && rm ~/miniconda.sh && /root/conda/bin/conda clean -tipsy && ln -s /root/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && echo ". /root/conda/etc/profile.d/conda.sh" >> ~/.bashrc && echo "conda activate cv_env" >> ~/.bashrc

#  将 /root/conda/bin 目录添加到环境变量 PATH 中，并将原有的 PATH 值追加在后面, 编辑 /etc/environment 文件, 再source
conda create -n cv_env python=3.7 -y

. /root/.bashrc

/root/conda/bin/conda init bash

conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/

conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

conda activate cv_env && conda info --envs

pip config set global.index-url pypi.mirrors.ustc.edu.cn
pip config set install.trusted-host https://pypi.mirrors.ustc.edu.cn/simple/

# common pkgs
# conda install 报错conda config --remove channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/
# conda config --remove channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

conda install jedi==0.17.2 nodejs==10.13.0 ipykernel==5.3.4 ipython==7.22.0 \
    jupyter==1.0.0 notebook==6.3.0 scipy==1.6.2 numpy==1.20.1 pandas==1.2.4 \
    sympy==1.8 nose==1.3.7 pillow==8.2.0 tqdm==4.59.0 \
    cython==0.29.23 h5py==2.8.0 lxml==4.6.3 pycrypto==2.6.1 rsa==4.7.2 \
    bokeh==1.4.0 astor==0.8.1 dask==2021.4.0 dataclasses==0.8 gast==0.4.0 \
    html5lib==1.1 pytest-runner==5.3.0 scikit-learn==0.24.1 simplegeneric==0.8.1 \
    toolz==0.11.1 typing==3.7.4.3 xlrd==2.0.1 xlwt==1.3.0

pip install opencv-python==4.7.0.72
pip install matplotlib==3.1.3 sklearn==0.0 sqlitedict==1.7.0 PyTurboJPEG==1.4.3 \
    opencv-contrib-python==4.7.0.72 pyyaml==5.2 pycocotools==2.0.2 \
    imgaug==0.4.0 albumentations==0.5.2 pylint==2.8.2 \
    jupyter_contrib_nbextensions==0.5.1

pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html

pip install torchsummary==1.5.1 fastai==1.0.61 timm==0.4.5 pytorch-lightning==1.2.10 onnxruntime-gpu==1.8.1

pip install fvcore==0.1.5.post20210812 \
    mmcv-full==1.3.3 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html

mkdir -p ~/public
cd ~/public 
git clone https://github.com/open-mmlab/mmdetection.git 
cd mmdetection && git checkout v2.13.0 && pip install -e . 
cd ~/public && git clone https://github.com/open-mmlab/mmsegmentation.git && \
cd mmsegmentation && git checkout v0.14.0 && pip install -e . && \
cd ~/public && git clone https://github.com/facebookresearch/detectron2.git && \
cd detectron2 && git checkout v0.5 && pip install -e .

rm /root/*.whl && \
rm -rf /root/conda/pkgs/* && \
rm -rf /root/.cache/pip/*

# 开启ssh 服务，前面已经配置好相关文件
service ssh start

# jupyter
jupyter-notebook password
nohup jupyter-notebook --no-browser --ip 0.0.0.0 --port 8340 --allow-root > jupyter.nohub.out &
http://192.168.1.6:8340/tree?

# 一些版本不匹配包处理 uninstall 
pip install jinja2==3.0.1


# commit 镜像
docker commit 46a4561f6d49 nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04-v1
```



### 2、使用dockerfile创建镜像:

基础镜像：nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

```shell
docker build -f Dockerfile-cuda11.2_u18.06_torch1.9 -t gtcv:v0 .
```

#### 2-1、Dockerfile-cuda11.2_u18.06_torch1.9: 

```dockerfile
FROM nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

RUN apt-get update && \
    apt-get install -y vim wget zip unrar tree git rsync ssh htop \
        inetutils-ping net-tools libgl1-mesa-glx \
        language-pack-zh-han* && \
    echo "LANG=zh_CN.UTF-8" > /etc/default/locale

RUN sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config  && \
    mkdir -p /var/run/sshd && \
    echo root:getech | chpasswd

# ********* conda/pip install **********
RUN echo " outter net ..." && \
    wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && \
    echo " wget ~/Miniconda3.sh done"

RUN /bin/bash ~/miniconda.sh -b -p /root/conda && \
    rm ~/miniconda.sh && \
    /root/conda/bin/conda clean -tipsy && \
    ln -s /root/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && \
    echo ". /root/conda/etc/profile.d/conda.sh" >> ~/.bashrc && \
    echo "conda activate cv_env" >> ~/.bashrc

ARG PIP_SOURCE=pypi.mirrors.ustc.edu.cn
ARG PIP_URL=https://pypi.mirrors.ustc.edu.cn/simple/

ENV PATH /root/conda/bin:$PATH
RUN conda create -n cv_env python=3.7 -y
RUN . /root/.bashrc && \
    /root/conda/bin/conda init bash && \
    # add channels
    conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/ && \
    # conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ && \
    conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ && \
    conda activate cv_env && conda info --envs && \
    pip config set global.index-url ${PIP_URL} && \
    pip config set install.trusted-host ${PIP_SOURCE} && \
    # common pkgs
    conda install -y jedi==0.17.2 nodejs==10.13.0 ipykernel==5.3.4 ipython==7.22.0 \
        jupyter==1.0.0 notebook==6.3.0 scipy==1.6.2 numpy==1.20.1 pandas==1.2.4 \
        sympy==1.8 nose==1.3.7 pillow==8.2.0 tqdm==4.59.0 opencv==4.5.5 \
        cython==0.29.23 h5py==2.8.0 lxml==4.6.3 pycrypto==2.6.1 rsa==4.7.2 \
        bokeh==1.4.0 astor==0.8.1 dask==2021.4.0 dataclasses==0.8 gast==0.4.0 \
        html5lib==1.1 pytest-runner==5.3.0 scikit-learn==0.24.1 simplegeneric==0.8.1 \
        toolz==0.11.1 typing==3.7.4.3 xlrd==2.0.1 xlwt==1.3.0 && \
    pip install matplotlib==3.1.3 sklearn==0.0 sqlitedict==1.7.0 PyTurboJPEG==1.4.3 \
        opencv-contrib-python==4.5.5 pyyaml==5.2 pycocotools==2.0.2 \
        imgaug==0.4.0 albumentations==0.5.2 pylint==2.8.2 \
        jupyter_contrib_nbextensions==0.5.1 && \
    jupyter contrib nbextension install && \
    # torch, fastai, detectron2, mmdet
    pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 \
        -f https://download.pytorch.org/whl/torch_stable.html && \      
    pip install torchsummary==1.5.1 fastai==1.0.61 \
        timm==0.4.5 pytorch-lightning==1.2.10 onnxruntime-gpu==1.8.1 && \
    # Note: please make sure mmcv_full version support mmdet and mmseg at the same time.
    pip install fvcore==0.1.5.post20210812 \
        # detectron2==0.4 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html \
        mmcv-full==1.3.3 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html \
        # mmdet==2.12.0 \
        && \
    mkdir -p ~/public && \
        cd ~/public && git clone https://github.com.cnpmjs.org/open-mmlab/mmdetection.git && \
        cd mmdetection && git checkout v2.13.0 && pip install -e . && \
        cd ~/public && git clone https://github.com.cnpmjs.org/open-mmlab/mmsegmentation.git && \
        cd mmsegmentation && git checkout v0.14.0 && pip install -e . && \
        cd ~/public && git clone https://github.com.cnpmjs.org/facebookresearch/detectron2.git && \
        cd detectron2 && git checkout v0.5 && pip install -e . \
        && \
    rm /root/*.whl && \
    rm -rf /root/conda/pkgs/* && \
    rm -rf /root/.cache/pip/*

# copy files
COPY public /root/public

# init ssh server
CMD ["/usr/sbin/sshd", "-D"]
```

#### 2-2、docker run:

```python
cmd_str="nvidia-docker run -dit --name ${docker_name} \
    -p ${port_prefix}22:22 \
    -p ${port_prefix}30-${port_prefix}99:${port_prefix}30-${port_prefix}99 \
    -v /etc/localtime:/etc/localtime \
    -v /var/tscvlm:/var/tscvlm \
    -v /etc/machine-id:/etc/machine-id \
    -v ${base_dir}/dataset/public:${dkr_base_dir}/dataset/public \
    -v $local_data_path:${dkr_base_dir}/dataset/$dir \
    -v $local_proj_path:${dkr_base_dir}/project/$dir \
    -v ${base_dir}/shared:${dkr_base_dir}/shared \
    -v ${local_pretrained_path}/_.torch:${dkr_base_dir}/.torch \
    -v ${local_pretrained_path}/_.cache:${dkr_base_dir}/.cache \
    -v /dev/shm:/dev/shm \
    --privileged \
    ${image}"
```

example:

```shell
nvidia-docker run -dit --name cv_algo_v1 -p 8322:22 -p 8330-8399:8330-8399 -v /etc/localtime:/etc/localtime -v /var/wdcvlm:/var/wdcvlm -v /var/tscvlm:/var/tscvlm -v /etc/machine-id:/etc/machine-id -v /data/algorithm/cv_algo/dataset/public:/root/dataset/public -v /data/algorithm/cv_algo/dataset/cv_algo:/root/dataset/cv_algo -v /data/algorithm/cv_algo/project/cv_algo:/root/project/cv_algo -v /data/algorithm/cv_algo/shared:/root/shared -v /data/algorithm/cv_algo/common/pretrained/_.torch:/root/.torch -v /data/algorithm/cv_algo/common/pretrained/_.cache:/root/.cache -v /dev/shm:/dev/shm --privileged nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04-v1
```



#### 2-3、docker compose 管理镜像：

#####  以前项目示例：

```yaml
version: '3.3'
services:  
  algorithma_sub1:
    image: yolov5_cu116:v3
    restart: always
    container_name: poros_bull_algorithma1
    ports:
      - "18502:8502"
      - "1882:22"
    working_dir: /src
    command: ["/bin/bash","/src/run_aside.sh"]
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["0"]
            capabilities: [gpu]
    volumes:
      - ./algorithm/sourceA:/src/
      - C:\\docker-compose-ox\\volume\\data\\cam:/data
      - D:\\BULL_DATA:/bull_data   
      - ./volume/data/algorithm:/output/   
      - type: bind
        source: ./mount
        target: /mount
        bind:
           propagation: shared
    networks:
      ox_smt:
        ipv4_address: 172.32.0.14
networks:
  ox_smt:
    ipam:
      config:
        - subnet: 172.32.0.0/24
        
```

##### 上海北坡示例：

```shell
# apt install docker-compose 安装的是1.25.0。 3.3版本按照以下命令安装
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/bin/docker-compose
sudo chmod +x /usr/bin/docker-compose
```

###### 命令行方式：

```shell
docker run -dit --name cv_algo_v1 -p 2502:8502 -p 2322:22 \
-v /etc/localtime:/etc/localtime -v /var/wdcvlm:/var/wdcvlm -v /var/tscvlm:/var/tscvlm -v /etc/machine-id:/etc/machine-id -v /data/algorithm/cv_algo/dataset/public:/root/dataset/public -v /data/algorithm/cv_algo/dataset/cv_algo:/root/dataset/cv_algo -v /data/algorithm/cv_algo/project/cv_algo:/root/project/cv_algo -v /data/algorithm/cv_algo/shared:/root/shared -v /data/algorithm/cv_algo/common/pretrained/_.torch:/root/.torch -v /data/algorithm/cv_algo/common/pretrained/_.cache:/root/.cache -v /dev/shm:/dev/shm \
 --gpus all \
 --privileged nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04-v1
```

###### docker-compose:

```yaml
version: '3.3'
services:
  algorithma_sub1:
    image: nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04-v1
    restart: always
    container_name: cv_algo_v1
    ports:
      - "2502:8502"
      - "2322:22"
    command: ["bash", "/root/project/cv_algo/bpglass/bp_glass/bp_glass_algo/algo_start.sh"]
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
    volumes:
      - /etc/localtime:/etc/localtime
      - /var/wdcvlm:/var/wdcvlm
      - /var/tscvlm:/var/tscvlm
      - /etc/machine-id:/etc/machine-id
      - /data/algorithm/cv_algo/dataset/public:/root/dataset/public
      - /data/algorithm/cv_algo/dataset/cv_algo:/root/dataset/cv_algo
      - /data/algorithm/cv_algo/project/cv_algo:/root/project/cv_algo
      - /data/algorithm/cv_algo/shared:/root/shared
      - /data/algorithm/cv_algo/common/pretrained/_.torch:/root/.torch
      - /data/algorithm/cv_algo/common/pretrained/_.cache:/root/.cache
      - /dev/shm:/dev/shm
    networks:
      ox_smt:
        ipv4_address: 172.32.0.14
networks:
  ox_smt:
    ipam:
      config:
        - subnet: 172.32.0.0/24

```

```python
# 构建和启动容器 这个命令会根据 docker-compose.yml 文件中的配置构建并启动所有的服务容器。
docker-compose up
# 启动容器（后台模式）
docker-compose up -d
# 停止容器：
docker-compose down
# 查看容器状态：
docker-compose ps
# 查看日志
docker-compose logs
```

```python
# docker save -o <output_file> <image_name>:<tag>
docker save -o bp_algo.tar nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04-v1

# nohup jupyter-notebook --no-browser --ip 0.0.0.0 --port 8340 --allow-root > jupyter.nohub.out &
# nohup jupyter-notebook --no-browser --ip 0.0.0.0 --port 9340 --allow-root > jupyter.nohub.out &
```



## 五、自动化方案概览

```

```





## 六、代码管理

```shell
git clone git@github.com:Du-Sen-Lin/Ind_Vision.git

# 本地密钥 密钥生成后需要在github上配置密钥id_rsa.pub本地才可以顺利访问ssh
ls -al ~/.ssh
ssh-keygen -t rsa

git add .
git commit -m 'Initial README.md in laptop'
git push origin main
# 多台电脑要习惯性拉取同步代码 git pull
```



## 七、服务器管理

```python
# vpn会导致重连wifi后本机ip改变无法远程，需要重启笔记本
# 重启服务器会出现 nvidia-smi驱动出问题 NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.
# 重新安装驱动：
./NVIDIA-Linux-x86_64-525.116.04.ru
# 启动docker
docker start wdcv
docker start cv_algo
# cv_algo 开启ssh 服务，前面已经配置好相关文件
service ssh start

nohup jupyter-notebook --no-browser --ip 0.0.0.0 --port 9340 --allow-root > jupyter.nohub.out &
nohup jupyter-notebook --no-browser --ip 0.0.0.0 --port 8340 --allow-root > jupyter.nohub.out &
```



路由只映射出一个端口的服务器：

```

```



## 八、工控机部署：

### 1、服务器调试：

#### 1-1、2张图请求信息示例：

```json
data = {
    "image_list": [{
            "roi": [],
            "template": [],
            "ocr_bbox": [],
            "bar_code": [],
            "comp_name": [],
            "src_img": "/root/project/wdcv/bpglass/bp_glass/bp_glass_algo/test_images/add_199.raw",
            "img_data": []
    }, {
            "roi": [],
            "template": [],
            "ocr_bbox": [],
            "bar_code": [],
            "comp_name": [],
            "src_img": "/root/project/wdcv/bpglass/bp_glass/bp_glass_algo/test_images/add_199.raw",
            "img_data": []
    }],
    "request_number": "b664028fb27a43df9b0d44002c93520c_12",
    "bar_code": [],
    "raw_height": 42000,
    "raw_width": 8192
}
```

#### 1-2、2张图返回信息示例：

```json
{
    "data": [{
        "bbox_res": [{
            "bboxs": [10, 20, 100, 200, 0.7],
            "label_name": "ng1"
        }, {
            "bboxs": [50, 100, 100, 200, 0.8],
            "label_name": "ng2"
        }],
        "img_path": "/root/dataset/wdcv/RuishengCamera/data_collection/data_20230518/NG/pic_1/16835576931_pic_1.bmp",
        "msg": "success!",
        "result": "OK",
        "roi": [],
        "status": "3"
    }, {
        "bbox_res": [{
            "bboxs": [10, 20, 100, 200, 0.7],
            "label_name": "ng1"
        }, {
            "bboxs": [50, 100, 100, 200, 0.8],
            "label_name": "ng2"
        }],
        "img_path": "/root/dataset/wdcv/RuishengCamera/data_collection/data_20230518/NG/pic_1/16835576931_pic_1.bmp",
        "msg": "success!",
        "result": "OK",
        "roi": [],
        "status": "3"
    }],
    "flag": "3",
    "image_number": 2,
    "message": "",
    "online_detect_time": "0",
    "request_number": "1668505976291"
}
```

启动服务：```python algo_service.py```

测试：```python send_msg_test.py```

### 2、工控机部署：

#### 2-1、算法包：

```
# gtcv包:gtcv-0.0.1-py3-none-any.whl
pip install gtcv-0.0.1-py3-none-any.whl
# 算法代码: bpglass 放在 /data/algorithm/bp_algo/project/bp_algo
```

#### 2-2、docker 启动

##### docker-compose:

1、安装：

```
# apt install docker-compose 安装的是1.25.0。 3.3版本按照以下命令安装
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/bin/docker-compose
sudo chmod +x /usr/bin/docker-compose
```

2、脚本：docker-compose.yml

```
version: '3.3'
services:
  algorithma_sub1:
    image: nvidia/cuda:11.7-cudnn8-devel-ubuntu18.04
    restart: always
    container_name: bp_algo
    ports:
      - "2502:8502"
      - "2322:22"
    command: ["bash", "/root/project/bp_algo/bpglass/bp_glass/bp_glass_algo/algo_start.sh"]
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
    volumes:
      - /etc/localtime:/etc/localtime
      - /var/wdcvlm:/var/wdcvlm      
      - /var/tscvlm:/var/tscvlm
      - /etc/machine-id:/etc/machine-id
      - /data/algorithm/bp_algo/dataset/public:/root/dataset/public
      - /data/algorithm/bp_algo/dataset/bp_algo:/root/dataset/bp_algo
      - /data/algorithm/bp_algo/project/bp_algo:/root/project/bp_algo
      - /data/algorithm/bp_algo/shared:/root/shared
      - /data/algorithm/bp_algo/common/pretrained/_.torch:/root/.torch
      - /data/algorithm/bp_algo/common/pretrained/_.cache:/root/.cache
      - /dev/shm:/dev/shm
    networks:
      ox_smt:
        ipv4_address: 172.32.0.14
networks:
  ox_smt:
    ipam:
      config:
        - subnet: 172.32.0.0/24


```

```
/root/project/bp_algo/bpglass/project/northglass/bp_glass_algo/config/config.json
```

